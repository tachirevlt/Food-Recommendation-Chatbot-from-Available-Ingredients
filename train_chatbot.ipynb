{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c1c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518df996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved offline! Shape: (1000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Tải dataset \n",
    "dataset = load_dataset(\"Schmitz005/recipe_nlg_dataset_sample\")\n",
    "\n",
    "# Chuyển thành DataFrame và lưu JSON\n",
    "df = dataset['train'].to_pandas() \n",
    "df.to_json('recipes_sample.json', orient='records', lines=True)\n",
    "print(\"Dataset saved offline! Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a060ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fecf559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   title                                        ingredients  \\\n",
      "0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
      "1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
      "2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
      "3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
      "4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
      "\n",
      "                                          directions  \\\n",
      "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
      "1  [\"Place chipped beef on bottom of baking dish....   \n",
      "2  [\"In a slow cooker, combine all ingredients. C...   \n",
      "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
      "4  [\"Combine first four ingredients and press in ...   \n",
      "\n",
      "                                              link    source  \\\n",
      "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
      "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
      "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
      "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
      "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
      "\n",
      "                                                 NER  \n",
      "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n",
      "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n",
      "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n",
      "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n",
      "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c886c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"chicken\", \"chicken gravy\", \"cream of mushroom soup\", \"shredded cheese\"]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NER\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308a22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 7)\n",
      "Columns: ['Unnamed: 0', 'title', 'ingredients', 'directions', 'link', 'source', 'NER']\n",
      "Sample NER (first row): [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]\n",
      "Sample ingredients (first row): [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_json('recipes_sample.json', orient='records', lines=True)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Sample NER (first row):\", df['NER'].iloc[0] if 'NER' in df.columns else \"No NER\")\n",
    "print(\"Sample ingredients (first row):\", df['ingredients'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7478abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample raw_ingredients (first 5): [['[\"1 c. firmly packed brown sugar\"', '\"1/2 c. evaporated milk\"', '\"1/2 tsp. vanilla\"', '\"1/2 c. broken nuts (pecans)\"', '\"2 tbsp. butter or margarine\"', '\"3 1/2 c. bite size shredded rice biscuits\"]'], ['[\"1 small jar chipped beef', 'cut up\"', '\"4 boned chicken breasts\"', '\"1 can cream of mushroom soup\"', '\"1 carton sour cream\"]'], ['[\"2 (16 oz.) pkg. frozen corn\"', '\"1 (8 oz.) pkg. cream cheese', 'cubed\"', '\"1/3 c. butter', 'cubed\"', '\"1/2 tsp. garlic powder\"', '\"1/2 tsp. salt\"', '\"1/4 tsp. pepper\"]'], ['[\"1 large whole chicken\"', '\"2 (10 1/2 oz.) cans chicken gravy\"', '\"1 (10 1/2 oz.) can cream of mushroom soup\"', '\"1 (6 oz.) box stove top stuffing\"', '\"4 oz. shredded cheese\"]'], ['[\"1 c. peanut butter\"', '\"3/4 c. graham cracker crumbs\"', '\"1 c. melted butter\"', '\"1 lb. (3 1/2 c.) powdered sugar\"', '\"1 large pkg. chocolate chips\"]']]\n",
      "Sample raw_str (first 5): ['[\"1 c. firmly packed brown sugar\" \"1/2 c. evaporated milk\" \"1/2 tsp. vanilla\" \"1/2 c. broken nuts (pecans)\" \"2 tbsp. butter or margarine\" \"3 1/2 c. bite size shredded rice biscuits\"]', '[\"1 small jar chipped beef cut up\" \"4 boned chicken breasts\" \"1 can cream of mushroom soup\" \"1 carton sour cream\"]', '[\"2 (16 oz.) pkg. frozen corn\" \"1 (8 oz.) pkg. cream cheese cubed\" \"1/3 c. butter cubed\" \"1/2 tsp. garlic powder\" \"1/2 tsp. salt\" \"1/4 tsp. pepper\"]', '[\"1 large whole chicken\" \"2 (10 1/2 oz.) cans chicken gravy\" \"1 (10 1/2 oz.) can cream of mushroom soup\" \"1 (6 oz.) box stove top stuffing\" \"4 oz. shredded cheese\"]', '[\"1 c. peanut butter\" \"3/4 c. graham cracker crumbs\" \"1 c. melted butter\" \"1 lb. (3 1/2 c.) powdered sugar\" \"1 large pkg. chocolate chips\"]']\n",
      "Any empty raw_str? False\n",
      "Non-empty rows: 1000\n"
     ]
    }
   ],
   "source": [
    "def extract_raw_ingredients(row):\n",
    "    raw_ings = []\n",
    "    # Từ NER (robust: handle list, tuple, dict)\n",
    "    if 'NER' in row and row['NER']:\n",
    "        ner_data = row['NER']\n",
    "        if isinstance(ner_data, str):\n",
    "            try:\n",
    "                ner_data = eval(ner_data)  # Nếu string, parse\n",
    "            except:\n",
    "                ner_data = []\n",
    "        if isinstance(ner_data, list):\n",
    "            for sublist in ner_data if isinstance(ner_data[0], list) else [ner_data]:\n",
    "                for entity in sublist:\n",
    "                    if isinstance(entity, (list, tuple, dict)):\n",
    "                        # Flexible: Tìm 'INGREDIENT' key hoặc index 2\n",
    "                        if isinstance(entity, dict) and 'type' in entity and entity['type'] == 'INGREDIENT':\n",
    "                            text = entity.get('text', entity.get('value', ''))\n",
    "                        elif len(entity) >= 4 and entity[2] == 'INGREDIENT':\n",
    "                            text = entity[3]\n",
    "                        else:\n",
    "                            continue\n",
    "                        clean_ing = re.sub(r'^\\s*\\d+(?:\\s+\\w+)*\\s+(.*)', r'\\1', str(text).lower()).strip()  # Regex rộng hơn: bỏ \"1 2/3 cup \" etc.\n",
    "                        if clean_ing and len(clean_ing) > 1 and clean_ing not in ['and', 'with', 'of']:  # Bỏ stop words thủ công\n",
    "                            raw_ings.append(clean_ing)\n",
    "        if raw_ings:\n",
    "            return raw_ings\n",
    "    \n",
    "    # Fallback mạnh từ ingredients: Split và clean\n",
    "    if isinstance(row['ingredients'], (list, str)):\n",
    "        if isinstance(row['ingredients'], str):\n",
    "            ings_list = row['ingredients'].split(',')  # Nếu string\n",
    "        else:\n",
    "            ings_list = row['ingredients']\n",
    "        for ing_text in ings_list:\n",
    "            clean_ing = re.sub(r'^\\s*\\d+(?:\\s+\\w+)*\\s+(.*)', r'\\1', str(ing_text).lower()).strip()\n",
    "            clean_ing = re.sub(r'^\\s*(a|an|the|of|with|and)\\s+(.*)', r'\\1', clean_ing)  # Bỏ stop words\n",
    "            if clean_ing and len(clean_ing) > 2:  # >2 để tránh \"a \", \"an\"\n",
    "                # Lấy từ cuối nếu nhiều (VD: \"sliced carrots\" → \"carrots\")\n",
    "                words = clean_ing.split()\n",
    "                if len(words) > 1 and words[0] in ['chopped', 'sliced', 'ground', 'diced']:\n",
    "                    clean_ing = ' '.join(words[1:])\n",
    "                raw_ings.append(clean_ing)\n",
    "    return raw_ings if raw_ings else ['unknown']  # Dummy nếu empty\n",
    "\n",
    "# Áp dụng\n",
    "df['raw_ingredients'] = df.apply(extract_raw_ingredients, axis=1)\n",
    "df['raw_str'] = df['raw_ingredients'].apply(lambda x: ' '.join(x) if x else 'unknown')\n",
    "\n",
    "# Debug chi tiết\n",
    "print(\"Sample raw_ingredients (first 5):\", df['raw_ingredients'].head().tolist())\n",
    "print(\"Sample raw_str (first 5):\", df['raw_str'].head().tolist())\n",
    "print(\"Any empty raw_str?\", df['raw_str'].str.strip().eq('').any())\n",
    "print(\"Non-empty rows:\", len(df[df['raw_str'].str.strip() != '']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d596a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF success! Vocab size: 1309\n",
      "Training done! Accuracy: 0.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean\n",
    "df = df[df['raw_str'].str.strip() != ''].dropna(subset=['title', 'directions'])\n",
    "\n",
    "# Vectorize: Thử TF-IDF, fallback CountVectorizer nếu empty\n",
    "try:\n",
    "    vectorizer = TfidfVectorizer(max_features=2000, stop_words=None, binary=True, min_df=1)  # Bỏ stop_words để an toàn\n",
    "    X = vectorizer.fit_transform(df['raw_str'])\n",
    "    if len(vectorizer.vocabulary_) == 0:\n",
    "        raise ValueError(\"Still empty\")\n",
    "    print(\"TF-IDF success! Vocab size:\", len(vectorizer.vocabulary_))\n",
    "except:\n",
    "    print(\"TF-IDF failed, using CountVectorizer\")\n",
    "    vectorizer = CountVectorizer(max_features=2000, stop_words=None, binary=True)\n",
    "    X = vectorizer.fit_transform(df['raw_str'])\n",
    "    print(\"CountVectorizer vocab size:\", len(vectorizer.vocabulary_))\n",
    "\n",
    "y = df['title']\n",
    "\n",
    "# Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Training done! Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91e6c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All saved! Check debug prints for raw_str.\n"
     ]
    }
   ],
   "source": [
    "# Lưu\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "joblib.dump(X, 'features_matrix.pkl')\n",
    "joblib.dump(model, 'recipe_model.pkl')\n",
    "df.to_pickle('recipes_df.pkl')\n",
    "print(\"All saved! Check debug prints for raw_str.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
