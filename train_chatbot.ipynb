{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518df996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved offline! Shape: (1000, 7)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Tải dataset \n",
    "dataset = load_dataset(\"Schmitz005/recipe_nlg_dataset_sample\")\n",
    "\n",
    "# Chuyển thành DataFrame và lưu JSON\n",
    "df = dataset['train'].to_pandas() \n",
    "df.to_json('recipes_sample.json', orient='records', lines=True)\n",
    "print(\"Dataset saved offline! Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a060ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fecf559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   title                                        ingredients  \\\n",
      "0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
      "1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
      "2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
      "3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
      "4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
      "\n",
      "                                          directions  \\\n",
      "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
      "1  [\"Place chipped beef on bottom of baking dish....   \n",
      "2  [\"In a slow cooker, combine all ingredients. C...   \n",
      "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
      "4  [\"Combine first four ingredients and press in ...   \n",
      "\n",
      "                                              link    source  \\\n",
      "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
      "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
      "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
      "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
      "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
      "\n",
      "                                                 NER  \n",
      "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n",
      "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n",
      "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n",
      "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n",
      "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c886c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"chicken\", \"chicken gravy\", \"cream of mushroom soup\", \"shredded cheese\"]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NER\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7478abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 7)\n",
      "Columns: ['Unnamed: 0', 'title', 'ingredients', 'directions', 'link', 'source', 'NER']\n",
      "Sample NER (first 3 rows): ['[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]', '[\"beef\", \"chicken breasts\", \"cream of mushroom soup\", \"sour cream\"]', '[\"frozen corn\", \"cream cheese\", \"butter\", \"garlic powder\", \"salt\", \"pepper\"]']\n",
      "Sample ingredients (first 3 rows): ['[\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]', '[\"1 small jar chipped beef, cut up\", \"4 boned chicken breasts\", \"1 can cream of mushroom soup\", \"1 carton sour cream\"]', '[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg. cream cheese, cubed\", \"1/3 c. butter, cubed\", \"1/2 tsp. garlic powder\", \"1/2 tsp. salt\", \"1/4 tsp. pepper\"]']\n",
      "Sample title (first 3 rows): ['No-Bake Nut Cookies', \"Jewell Ball'S Chicken\", 'Creamy Corn']\n",
      "Cleaned shape: (1000, 7)\n",
      "Any empty NER? False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "# Load data offline\n",
    "try:\n",
    "    df = pd.read_json('recipes_sample.json', orient='records', lines=True)\n",
    "except ValueError as e:\n",
    "    print(f\"JSON error: {e}. Anh check file 'recipes_sample.json' xem có đúng format không nhé!\")\n",
    "\n",
    "# Debug: Check columns và data\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Sample NER (first 3 rows):\", df['NER'].head(3).tolist())\n",
    "print(\"Sample ingredients (first 3 rows):\", df['ingredients'].head(3).tolist())\n",
    "print(\"Sample title (first 3 rows):\", df['title'].head(3).tolist())\n",
    "\n",
    "# Clean data: Drop NaN ở NER và ingredients, đảm bảo NER là list\n",
    "df = df.dropna(subset=['NER', 'ingredients'])\n",
    "df['NER'] = df['NER'].apply(lambda x: x if isinstance(x, list) else eval(x) if isinstance(x, str) else [])\n",
    "df['ingredients'] = df['ingredients'].apply(lambda x: x if isinstance(x, list) else eval(x) if isinstance(x, str) else [])\n",
    "df = df[df['NER'].apply(len) > 0]  # Drop row thiếu NER\n",
    "df = df[df['ingredients'].apply(len) > 0]  # Drop row thiếu ingredients\n",
    "\n",
    "# Kiểm tra lại\n",
    "print(\"Cleaned shape:\", df.shape)\n",
    "print(\"Any empty NER?\", df['NER'].apply(len).eq(0).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d43798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ner_str (first 3): ['brown sugar milk vanilla nuts butter bite size shredded rice biscuits', 'beef chicken breasts cream of mushroom soup sour cream', 'frozen corn cream cheese butter garlic powder salt pepper']\n",
      "Any empty ner_str? False\n",
      "Final cleaned shape: (1000, 8)\n",
      "Preprocess done! X shape: (1000, 719)\n",
      "Vocabulary size: 719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tạo ner_str từ NER\n",
    "def create_ner_str(row):\n",
    "    ner = row['NER']\n",
    "    if isinstance(ner, list):\n",
    "        return ' '.join([tag.lower() for tag in ner if isinstance(tag, str) and tag])\n",
    "    elif isinstance(ner, dict):\n",
    "        return ' '.join([tag.lower() for tag in ner.values() if isinstance(tag, str) and tag])\n",
    "    return ''  # Fallback nếu NER sai format\n",
    "\n",
    "df['ner_str'] = df.apply(create_ner_str, axis=1)\n",
    "\n",
    "# Debug: Check ner_str\n",
    "print(\"Sample ner_str (first 3):\", df['ner_str'].head(3).tolist())\n",
    "print(\"Any empty ner_str?\", df['ner_str'].str.strip().eq('').any())\n",
    "\n",
    "# Drop empty ner_str\n",
    "df = df[df['ner_str'].str.strip() != '']\n",
    "print(\"Final cleaned shape:\", df.shape)\n",
    "\n",
    "# Tạo TF-IDF trên ner_str\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', binary=True, min_df=1)\n",
    "X = vectorizer.fit_transform(df['ner_str'])\n",
    "\n",
    "# Target\n",
    "y = df['title']\n",
    "\n",
    "# Lưu\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "joblib.dump(X, 'features_matrix.pkl')\n",
    "df.to_pickle('recipes_df.pkl')\n",
    "print(\"Preprocess done! X shape:\", X.shape)\n",
    "print(\"Vocabulary size:\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54dd8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done! Accuracy: 0.035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['recipe_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load từ preprocess\n",
    "X = joblib.load('features_matrix.pkl')\n",
    "y = df['title']\n",
    "\n",
    "# Option 1: Cosine Similarity (không train, dùng X để match)\n",
    "# Sẵn sàng!\n",
    "\n",
    "# Option 2: Supervised - RandomForest\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Training done! Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Lưu\n",
    "joblib.dump(model, 'recipe_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
